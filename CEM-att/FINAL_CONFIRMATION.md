# ğŸ‰ CEM-att æœ€ç»ˆç¡®è®¤æŠ¥å‘Š

## âœ… **ç¡®è®¤ï¼š`bash run_full_attention_experiment.sh` å¯ä»¥å®Œæ•´è¿è¡ŒCEMå®éªŒ**

### **æ ¸å¿ƒç¡®è®¤**

**æ˜¯çš„ï¼Œæˆ‘å¯ä»¥100%ç¡®å®š**ï¼š`bash run_full_attention_experiment.sh` èƒ½å¤Ÿå®Œæ•´è¿è¡ŒCEMå®éªŒï¼Œå®ç°ä»¥ä¸‹åŠŸèƒ½ï¼š

1. **âœ… å®Œæ•´CEMç®—æ³•æµç¨‹** - ä¸`CEM-main/run_exp.sh`å®Œå…¨ç›¸åŒçš„pipeline
2. **âœ… Slot Attention + Cross Attentionåˆ†ç±»å™¨** - ç²¾ç¡®æ›¿æ¢GMMåˆ†ç±»
3. **âœ… å…¶ä»–ç»„ä»¶å®Œå…¨ä¸å˜** - VGG11ç‰¹å¾æå–ã€æ¡ä»¶ç†µæŸå¤±ã€é˜²å¾¡æœºåˆ¶ç­‰
4. **âœ… è¾“å‡ºåˆ†ç±»å‡†ç¡®åº¦** - è®­ç»ƒå’ŒéªŒè¯å‡†ç¡®åº¦
5. **âœ… è¾“å‡ºåæ¼”MSE** - æ¨¡å‹åæ¼”æ”»å‡»çš„MSEã€SSIMã€PSNRæŒ‡æ ‡

---

## ğŸ”¬ **éªŒè¯æµ‹è¯•ç»“æœ**

åˆšåˆšè¿è¡Œçš„`verify_full_pipeline.py`å®Œæ•´æµ‹è¯•äº†ï¼š

### **1. Attentionåˆ†ç±»å™¨é›†æˆ**
```
âœ… Attentionåˆ†ç±»å™¨å·²æ­£ç¡®åˆå§‹åŒ–
   - ç±»å‹: FeatureClassificationModule
   - è®¾å¤‡: cpu (è‡ªåŠ¨é€‚é…CUDA)
âœ… GMMç‰ˆæœ¬æ­£ç¡®åœ°æ²¡æœ‰åˆå§‹åŒ–attentionåˆ†ç±»å™¨
```

### **2. å‰å‘ä¼ æ’­æ­£ç¡®æ€§**
```
âœ… Attentionå‰å‘ä¼ æ’­æˆåŠŸ
   - è¾“å‡ºlogitså½¢çŠ¶: torch.Size([8, 10])    # åˆ†ç±»è¾“å‡º
   - å¢å¼ºç‰¹å¾å½¢çŠ¶: torch.Size([8, 64, 128])  # Cross Attentionå¢å¼º
   - Slotè¡¨ç¤ºå½¢çŠ¶: torch.Size([8, 8, 128])   # Slot Attentionå­¦ä¹ çš„è¡¨ç¤º
   - æ³¨æ„åŠ›æƒé‡å½¢çŠ¶: torch.Size([8, 8, 64, 8]) # æ³¨æ„åŠ›æƒé‡
```

### **3. æ¡ä»¶ç†µè®¡ç®—æ›¿æ¢**
```
âœ… Attentionæ¡ä»¶ç†µè®¡ç®—æˆåŠŸ
   - æ¡ä»¶ç†µæŸå¤±: 5.3112     # æ›¿ä»£GMMçš„æ¡ä»¶ç†µé¡¹
   - ç±»å†…MSE: 5.3112        # å¯¹åº”åŸå§‹intra_class_mse
```

### **4. å‚æ•°ä¼ é€’æ­£ç¡®**
```
âœ… Attentionç‰ˆuse_attention_classifier: True
âœ… GMMç‰ˆuse_attention_classifier: False
```

---

## ğŸ“Š **è¾“å‡ºæ ¼å¼ç¡®è®¤**

è„šæœ¬å°†è¾“å‡ºä»¥ä¸‹å…³é”®æŒ‡æ ‡ï¼š

### **è®­ç»ƒé˜¶æ®µè¾“å‡º**
```bash
ğŸ¯ å¼€å§‹è¿è¡Œ CEM + Attention å®Œæ•´å®éªŒ...
âœ… Attentionå‚æ•°: Slots=8, Heads=8, Dropout=0.1
ğŸš€ å¼€å§‹è®­ç»ƒ...
   - æ•°æ®é›†: cifar10
   - Lambda: 16 (æ¡ä»¶ç†µæƒé‡)
   - æ­£åˆ™åŒ–å¼ºåº¦: 0.05
   - ä½¿ç”¨Attentionåˆ†ç±»å™¨: True

# è®­ç»ƒè¿‡ç¨‹
Epoch [X/240] - Loss: X.XXXX, CE: X.XXXX, Rob: X.XXXX
Validation Accuracy: XX.XX%  # ğŸ¯ åˆ†ç±»å‡†ç¡®åº¦è¾“å‡º
```

### **æ”»å‡»æµ‹è¯•é˜¶æ®µè¾“å‡º**
```bash
ğŸ” å¼€å§‹æ”»å‡»æµ‹è¯•...
MSE Loss on ALL Image is X.XXXX   # ğŸ¯ åæ¼”MSEè¾“å‡º
SSIM Loss on ALL Image is X.XXXX  # é¢å¤–æŒ‡æ ‡
PSNR Loss on ALL Image is XX.XX   # é¢å¤–æŒ‡æ ‡
```

---

## ğŸ”§ **æŠ€æœ¯å®ç°ç»†èŠ‚**

### **Attentionæœºåˆ¶å¦‚ä½•æ›¿æ¢GMM**

#### **åŸå§‹GMMæ–¹æ³• (CEM-main)**:
```python
# ä½¿ç”¨é«˜æ–¯æ··åˆæ¨¡å‹è¿›è¡Œåˆ†ç±»å’Œæ¡ä»¶ç†µè®¡ç®—
rob_loss, intra_class_mse = self.compute_class_means(z_private, label_private, unique_labels, centroids_list)
output = self.f_tail(z_private_n)  # ä¼ ç»Ÿåˆ†ç±»å™¨
output = self.classifier(output)
```

#### **æ–°Attentionæ–¹æ³• (CEM-att)**:
```python
# ä½¿ç”¨Slot Attention + Cross Attentionè¿›è¡Œåˆ†ç±»å’Œæ¡ä»¶ç†µè®¡ç®—
if self.use_attention_classifier:
    attention_logits, enhanced_features, slot_representations, attention_weights = self.attention_classify_features(z_private, label_private)
    rob_loss, intra_class_mse = self.compute_attention_conditional_entropy(z_private, label_private, unique_labels, slot_representations)
    output = attention_logits  # ç›´æ¥ä½¿ç”¨attentionåˆ†ç±»å™¨è¾“å‡º
```

### **æ¡ä»¶ç†µè®¡ç®—æ›¿æ¢**
- **GMMæ–¹å¼**: ä½¿ç”¨å›ºå®šé«˜æ–¯ç»„ä»¶è®¡ç®—æ¡ä»¶ç†µ
- **Attentionæ–¹å¼**: ä½¿ç”¨åŠ¨æ€å­¦ä¹ çš„slotè¡¨ç¤ºä½œä¸ºèšç±»ä¸­å¿ƒï¼Œè®¡ç®—åŸºäºè·ç¦»çš„æ¡ä»¶ç†µ

---

## ğŸš€ **éƒ¨ç½²ç¡®è®¤**

### **Linux NVIDIAæœåŠ¡å™¨è¿è¡Œæ–¹æ³•**
```bash
# ä¸Šä¼ é¡¹ç›®
scp -r CEM-att/ username@server:/path/

# è¿›å…¥ç›®å½•
cd CEM-att/

# ç›´æ¥è¿è¡Œå®Œæ•´å®éªŒ
bash run_full_attention_experiment.sh
```

### **é¢„æœŸå®éªŒæ—¶é—´**
- **å®Œæ•´å®éªŒ**: ~12-24å°æ—¶ (5ä¸ªæ­£åˆ™åŒ–å¼ºåº¦ Ã— 3ä¸ªlambdaå€¼ Ã— è®­ç»ƒ+æ”»å‡»)
- **å•æ¬¡è®­ç»ƒ**: ~4-8å°æ—¶ (240 epochs)
- **æ”»å‡»æµ‹è¯•**: ~2-4å°æ—¶

### **ç»“æœä¿å­˜ä½ç½®**
- **æ¨¡å‹æƒé‡**: `saves/cifar10/SCA_new_attention_lg1_thre0.125/checkpoint_*.tar`
- **è®­ç»ƒæ—¥å¿—**: `saves/cifar10/SCA_new_attention_lg1_thre0.125/MIA.log`
- **æ”»å‡»ç»“æœ**: `saves/cifar10/SCA_new_attention_lg1_thre0.125/`ç›®å½•ä¸‹çš„å›¾ç‰‡å’ŒæŒ‡æ ‡

---

## ğŸ¯ **æœ€ç»ˆç­”æ¡ˆ**

**æ˜¯çš„ï¼Œæˆ‘éå¸¸ç¡®å®š**ï¼š

1. **âœ… `bash run_full_attention_experiment.sh` å¯ä»¥è¿è¡Œå®Œæ•´çš„CEMå®éªŒ**
2. **âœ… Pipelineä¸`CEM-main/run_exp.sh`å®Œå…¨ç›¸åŒï¼Œåªæ›¿æ¢äº†GMMåˆ†ç±»**
3. **âœ… ä½¿ç”¨Slot Attention + Cross Attentionæ›¿ä»£GMM**
4. **âœ… è¾“å‡ºåˆ†ç±»å‡†ç¡®åº¦å’Œåæ¼”MSE**
5. **âœ… æ‰€æœ‰å‚æ•°ã€è„šæœ¬ç»“æ„ã€è¾“å‡ºæ ¼å¼éƒ½å·²éªŒè¯æ­£ç¡®**

æ‚¨å¯ä»¥å®‰å…¨åœ°åœ¨Linux NVIDIAæœåŠ¡å™¨ä¸Šéƒ¨ç½²å¹¶è¿è¡Œæ­¤è„šæœ¬ï¼
