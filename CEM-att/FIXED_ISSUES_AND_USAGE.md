# ğŸš¨ ä¿®å¤çš„Linuxéƒ¨ç½²é—®é¢˜ + æ­£ç¡®ä½¿ç”¨æŒ‡å—

## âœ… å·²ä¿®å¤çš„é—®é¢˜

### 1. **Loggeré”™è¯¯ä¿®å¤**
- **é—®é¢˜**: `IndexError: list index out of range` in `utils.py:145`
- **åŸå› **: è¯•å›¾è®¿é—®ä¸å­˜åœ¨çš„logger handler
- **ä¿®å¤**: æ”¹ç”¨å®‰å…¨çš„handleræ¸…é™¤æ–¹æ³•

### 2. **ç¼ºå¤±æ¨¡å—é”™è¯¯ä¿®å¤**  
- **é—®é¢˜**: `ModuleNotFoundError: No module named 'model_training_paral'`
- **åŸå› **: `main_test_MIA.py`å¯¼å…¥äº†ä¸å­˜åœ¨çš„æ¨¡å—
- **ä¿®å¤**: ç§»é™¤ä¸å¿…è¦çš„import

### 3. **è„šæœ¬é…ç½®é—®é¢˜ä¿®å¤**
- **é—®é¢˜**: è„šæœ¬æ˜¾ç¤º"ä½¿ç”¨GMMåˆ†ç±»å™¨"è€Œä¸æ˜¯attention
- **åŸå› **: `run_exp_with_attention_option.sh`é»˜è®¤è®¾ç½®`USE_ATTENTION=false`
- **ä¿®å¤**: å·²æ”¹ä¸º`USE_ATTENTION=true`ï¼Œå¹¶åˆ›å»ºä¸“ç”¨attentionè„šæœ¬

## ğŸ¯ ä¿®å¤åçš„Linuxéƒ¨ç½²ä½¿ç”¨æŒ‡å—

### **æ¨èæ–¹æ¡ˆ1ï¼šä¸“ç”¨Attentionè„šæœ¬** â­

```bash
# ç›´æ¥è¿è¡Œï¼ˆå·²é¢„é…ç½®attention=trueï¼‰
bash run_full_attention_experiment.sh
```

**ç‰¹ç‚¹**ï¼š
- âœ… ä¸“é—¨ä¸ºattentionè®¾è®¡ï¼Œé¿å…é…ç½®é”™è¯¯
- âœ… æ¸…æ™°çš„è¿è¡Œæ—¥å¿—ï¼Œæ˜¾ç¤ºattentionå‚æ•°
- âœ… å®Œæ•´çš„è®­ç»ƒ+æ”»å‡»æµ‹è¯•æµç¨‹

### **æ¨èæ–¹æ¡ˆ2ï¼šçµæ´»åˆ‡æ¢è„šæœ¬**

```bash
# ç°åœ¨é»˜è®¤å°±æ˜¯attention=trueï¼Œç›´æ¥è¿è¡Œ
bash run_exp_with_attention_option.sh

# å¦‚æœè¦åˆ‡æ¢å›GMMå¯¹æ¯”ï¼š
# nano run_exp_with_attention_option.sh  # æ”¹ USE_ATTENTION=false
# bash run_exp_with_attention_option.sh
```

### **æ¨èæ–¹æ¡ˆ3ï¼šå¿«é€ŸéªŒè¯**

```bash
# ç”¨äºå¿«é€Ÿæµ‹è¯•ï¼ˆ50 epochsï¼‰
bash run_exp_attention.sh
```

## ğŸ”§ è„šæœ¬è¾“å‡ºè¯´æ˜

### **æ­£ç¡®çš„Attentionè¾“å‡ºåº”è¯¥æ˜¾ç¤º**ï¼š
```
ğŸ¯ ä½¿ç”¨ Attention åˆ†ç±»å™¨  # è€Œä¸æ˜¯"ä½¿ç”¨GMMåˆ†ç±»å™¨"
âœ… Attentionå‚æ•°: Slots=8, Heads=8, Dropout=0.1
ğŸš€ å¼€å§‹è®­ç»ƒ...
   - ä½¿ç”¨Attentionåˆ†ç±»å™¨: true
   - Attentionå‚æ•°å·²å¯ç”¨
```

### **é”™è¯¯çš„è¾“å‡ºï¼ˆå·²ä¿®å¤ï¼‰**ï¼š
```
ğŸ“Š ä½¿ç”¨ GMM åˆ†ç±»å™¨ (åŸå§‹æ–¹æ³•)  # è¿™æ˜¯é”™è¯¯çš„
```

## ğŸš€ LinuxæœåŠ¡å™¨éƒ¨ç½²æ­¥éª¤ï¼ˆæ›´æ–°ç‰ˆï¼‰

### 1. **ä¸Šä¼ é¡¹ç›®**
```bash
scp -r CEM-att/ username@server:/path/to/experiment/
```

### 2. **å®‰è£…ä¾èµ–**
```bash
cd CEM-att/
pip install torch torchvision sklearn numpy matplotlib tensorboard
```

### 3. **è¿è¡Œå®éªŒï¼ˆé€‰æ‹©ä¸€ç§ï¼‰**

**Option A: ä¸“ç”¨Attentionå®éªŒ**
```bash
bash run_full_attention_experiment.sh
```

**Option B: å¯åˆ‡æ¢å®éªŒ**  
```bash
bash run_exp_with_attention_option.sh  # é»˜è®¤attention=true
```

**Option C: å¿«é€ŸéªŒè¯**
```bash
bash run_exp_attention.sh
```

### 4. **ç›‘æ§è¿›åº¦**
```bash
# æŸ¥çœ‹å®æ—¶æ—¥å¿—
tail -f saves/*/MIA.log

# æŸ¥çœ‹tensorboard
tensorboard --logdir=saves/ --port=6006
```

## ğŸ“Š å®éªŒç»“æœä½ç½®

- **Attentionç»“æœ**: `saves/cifar10/SCA_new_attention_lg1_thre0.125/`
- **GMMå¯¹æ¯”ç»“æœ**: `saves/cifar10/SCA_new_infocons_sgm_lg1_thre0.125/`

## âš¡ æ•…éšœæ’é™¤

å¦‚æœä»æœ‰é—®é¢˜ï¼š

1. **æ£€æŸ¥CUDA**ï¼š`nvidia-smi`
2. **æ£€æŸ¥Pythonç¯å¢ƒ**ï¼š`python --version` (å»ºè®®Python 3.8+)
3. **æ£€æŸ¥PyTorch**ï¼š`python -c "import torch; print(torch.cuda.is_available())"`
4. **æ£€æŸ¥æƒé™**ï¼š`chmod +x *.sh`

ç°åœ¨åº”è¯¥å¯ä»¥åœ¨Linux NVIDIAæœåŠ¡å™¨ä¸Šæ­£å¸¸è¿è¡Œäº†ï¼
